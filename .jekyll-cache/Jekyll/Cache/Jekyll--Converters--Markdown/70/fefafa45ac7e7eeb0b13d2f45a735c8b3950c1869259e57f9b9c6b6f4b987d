I"Ô<h1 id="introduction">Introduction</h1>

<h2 id="motivation">Motivation</h2>

<p>Modern deep learning methods are very sensitive to many hyperparameters, but the current search method has some limitations</p>

<ol>
  <li>Vanilla Bayesian hyperparameter optimization is computationally infeasible.
    <ul>
      <li>BO normally uses GP as a probabilistic model, but GP cannot scale well in high dimensions and exhibit cubic complexity in the number of data points.  (bad scalability);)</li>
      <li>GP requires a special kernel to apply to complex configuration spaces. (bad flexibility))</li>
    </ul>
  </li>
  <li>Bandit-based evaluation <strong>based on random search</strong> (Hyperbandit) lacks guidance and cannot converge to the best configurations quickly.
    <ul>
      <li>it only samples **configurations randomly **at each ieration and does not learn from previously sampled configurations.</li>
      <li>It can lead to worse final performance than the model-based approach.</li>
    </ul>
  </li>
</ol>

<h2 id="contribution">Contribution</h2>

<p>The paper proposes the BOHB algorithm by combining BO and the bandit-based approach. BOHB can achieve <strong>strong anytime performance and fast convergence to optimal configurations.</strong></p>

<p>It consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types. (SVM, NN, Bayesian NN, Deep RL, CNN)</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220518142102146.png" alt="image-20220518142102146" /></p>

<h1 id="design-target">Design target</h1>

<ol>
  <li><strong>Strong Anytime Performance</strong>: HPO methods must yield good configurations with such a small budget.</li>
  <li><strong>Strong Final performance</strong></li>
  <li><strong>Effective use of parallel resources</strong></li>
  <li><strong>Scalability</strong> The algorithm must handle problems ranging from just a few to many dozens of hyperparameters.</li>
  <li><strong>Robustness &amp; Flexibility</strong> The algorithm can handle different types of hyperparameters, binary, integer, continuous and categorical,</li>
</ol>

<h1 id="bohb">BOHB</h1>

<p>BOHB relies on HB to determine how many configurations to evaluate with which budget, but it replaces the random selection of configurations at the beginning of each HB iteration by a model-based search.</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220518153213202.png" alt="image-20220518153213202" /></p>

<h2 id="parallelization">Parallelization</h2>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220519163907311.png" alt="image-20220519163907311" /></p>

<ol>
  <li>The resulting model is shared across all SH runs</li>
  <li>Each worker will either sample a new configuration or run the next SH run in parallel.</li>
  <li>starting different iterations at the same time</li>
</ol>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220518153256585.png" alt="image-20220518153256585" /></p>

<h1 id="evaluation">Evaluation</h1>

<h2 id="counting-ones">Counting ones</h2>

<p>The paper defines a problem with the following :</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220518160704652.png" alt="image-20220518160704652" /></p>

<p>This can Investigate BOHBâ€™s behavior in high-dimensional mixed continuous/categorical configuration spaces (Ncat = 8 and Ncont = 8 parameters.). It uses SMAC since the random forest are known to perform well in high-dimensional categorical spaces. Test cfgs:</p>

<ol>
  <li>Budget: number of samples,</li>
  <li>For each method, we performed 512 independent runs and report the immediate regret.</li>
</ol>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220518153851984.png" alt="image-20220518153851984" /></p>

<h2 id="svm">SVM</h2>

<p>And then the paper measured SVMâ€™s error on the different search algorithms. And the search target is the hyperparameters in RBF kernel.(the regularization parameter C and the kernel parameter ).</p>

<p>The budget is a number of training data points.</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220518155209472.png" alt="image-20220518155209472" /></p>

<h2 id="rl-and-bnn">RL and BNN</h2>

<p>Finally, the paper measures the BOHB on Bayesian Neural Networks, Reinforcement learning ( eight hyperparameters of proximal policy optimization) to learn cart-pole swing-up task, and CNN task on cifar10.</p>

<h2 id="cnn">CNN</h2>

<p>As for CNN for cifar10, the paper run BOHB with the following cfgs:</p>

<ol>
  <li>Search target: Learning rate, momentum, weight decay, and batch size.</li>
  <li>budget: epoch, 22,66,200, 600</li>
  <li>19 parallel workers, each with 2 GPUs for parallel training</li>
</ol>

<p>The complete BOHB run of 16 iterations required a total of 33 GPU days, and achieve 2.78% test error.</p>

:ET