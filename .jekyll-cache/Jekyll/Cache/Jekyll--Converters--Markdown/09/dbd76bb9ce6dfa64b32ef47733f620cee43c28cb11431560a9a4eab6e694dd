I"'<p><strong>Motivation:</strong> Mainly focus on storing small to medium size key-values on fast storage – flash devices or in-memory.</p>

<p><strong>Storage:</strong> RocksDB is a storage engine with key/value interface. It uses a Log-Structured Database Engine for storage and supports various compression algorithms.</p>

<p><strong>Performance:</strong> Support efficient point lookups, range scans, and different types of ACID guarantees.</p>

<h1 id="high-level-architecture">High Level Architecture</h1>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20211014141909023.png" alt="image-20211014141909023" /></p>

<p>RocksDB organizes all data in sorted order and the common operations are <code>Get(key)</code>, <code>NewIterator()</code>, <code>Put(key, val)</code>, <code>Delete(key)</code>, and <code>SingleDelete(key)</code>.</p>

<p>The three basic constructs of RocksDB are <strong>memtable</strong>, <strong>sstfile</strong> and <strong>logfile</strong>. The <a href="https://github.com/facebook/rocksdb/wiki/MemTable"><strong>memtable</strong></a> is an in-memory data structure - new writes are inserted into the <em>memtable</em> and are optionally written to the <a href="https://github.com/facebook/rocksdb/wiki/Write-Ahead-Log"><strong>logfile</strong> (aka. Write Ahead Log(WAL))</a>. The logfile is a sequentially-written file on storage. When the memtable fills up, it is flushed to a <a href="https://github.com/facebook/rocksdb/wiki/Rocksdb-BlockBasedTable-Format"><strong>sstfile</strong></a> on storage and the corresponding logfile can be safely deleted. The data in an sstfile is sorted to facilitate easy lookup of keys.</p>

<h1 id="features-overview">Features overview</h1>

<p>All <strong>data</strong> in the <strong>database</strong> is logically arranged <strong>in sorted order</strong></p>

<h2 id="column-families">Column Families</h2>

<p>partitioning a database instance into multiple column families</p>

<p>RocksDB guarantees users a consistent view across column families, including after crash recovery when WAL is enabled or atomic flush is enabled.</p>

<p>It also supports atomic cross-column family operations via the <code>WriteBatch</code> API.</p>

<h2 id="update">Update</h2>

<p><strong>Put</strong>: update a single</p>

<p><strong>Write</strong>: update batch of data</p>

<h2 id="gets-iterators-and-snapshots">Gets, Iterators and Snapshots</h2>

<p><strong>get</strong>: single key</p>

<p><strong>multiGet</strong>: many kv pairs</p>

<p><strong>Iterator</strong>: range scan on the database. Seek to a specified key and then the application can start scanning one key at a time from that point</p>

<p><strong>Snapshots:</strong> create a point-in-time view of a database</p>

<p>Short-lived/foreground scans are best done via an iterator while long-running/background scans are better done via a snapshot.</p>

<p>An <code>Iterator</code> keeps a reference count on all underlying files that correspond to that point-in-time-view of the database - these files are not deleted until the <code>Iterator</code> is released. A <code>Snapshot</code>, on the other hand, does not prevent file deletions; instead the compaction process understands the existence of <code>Snapshots</code> and promises never to delete a key that is visible in any existing <code>Snapshot</code>.</p>

<p><code>Snapshots</code> are not persisted across database restarts: a reload of the RocksDB library (via a server restart) releases all pre-existing <code>Snapshots</code>.</p>

<h2 id="transactions">Transactions</h2>

<p>multi-operational transactions. It supports both of optimistic and pessimistic mode</p>

<h2 id="prefix-iterators">Prefix Iterators</h2>

<p>Options.prefix_extractor<code> is set, a hash of the prefix is also added to the Bloom. An </code>Iterator<code> that specifies a key-prefix (in </code>ReadOptions`) will use the <a href="https://github.com/facebook/rocksdb/wiki/RocksDB-Bloom-Filter">Bloom Filter</a> to avoid looking into data files that do not contain keys with the specified key-prefix</p>

<h2 id="persistence">Persistence</h2>

<p>RocksDB has a <a href="https://github.com/facebook/rocksdb/wiki/Write-Ahead-Log">Write Ahead Log</a> (WAL). All write operations (<code>Put</code>, <code>Delete</code> and <code>Merge</code>) are stored in an in-memory buffer called the memtable as well as <strong>optionally</strong> inserted into WAL. On restart, it re-processes all the transactions that were recorded in the log.</p>

<p>WAL can be configured to be stored in a directory different from the directory where the SST files are stored</p>

<h2 id="data-checksuming">Data CheckSuming</h2>

<p>RocksDB uses a checksum to detect corruptions in storage. These checksums are for each SST file block (typically between <code>4K</code> to <code>128K</code> in size). A block, once written to storage, is never modified.</p>

<h2 id="multi-threaded-compactions">Multi-Threaded Compactions</h2>

<p>It is observed that sustained write rates may increase by as much as a factor of 10 with multi-threaded compaction when the database is on SSDs, as compared to single-threaded compactions</p>

<h2 id="compaction-sytles">Compaction sytles</h2>

<p>Support:</p>

<ol>
  <li>Level Style Compaction.</li>
  <li>Universal Style Compaction</li>
  <li>FIFO Style Compaction</li>
  <li>Customer compaction</li>
</ol>

<h2 id="metadata-storage">metadata storage</h2>

<p>A manifest log file is used to record all the database state changes. Add/delete files etc.</p>

<h2 id="avoiding-stalls">Avoiding Stalls</h2>

<p>keep a small set of threads explicitly reserved for the sole purpose of flushing <em>memtable</em> to storage.</p>

<h2 id="compaction-filter">Compaction Filter</h2>

<p>Can drop a key or modify the value of key as part of compaction process</p>

<h2 id="readonly-mode">ReadOnly Mode</h2>

<p>much higher read performance because oft-traversed code paths avoid locks completely.</p>

<h2 id="data-compression">Data Compression</h2>

<p>supports lz4, zstd, snappy, zlib, and lz4_hc compression</p>

<h2 id="full-backups-and-replication">Full Backups and Replication</h2>

<p>RocksDB itself is not a replicated, but it provides some helper functions to enable users to implement their replication system on top of RocksDB</p>

<h2 id="block-cache--compressed-and-uncompressed-data">Block Cache – Compressed and Uncompressed Data</h2>

<p>RocksDB uses a <a href="https://github.com/facebook/rocksdb/wiki/Block-Cache">LRU cache for blocks</a> to serve reads. The block cache is partitioned into two individual caches: the first caches uncompressed blocks and the second caches compressed blocks in RAM. If a compressed block cache is configured, users may wish to enable direct I/O to prevent redundant caching of the same data in OS page cache.</p>

<h2 id="table-cache">Table Cache</h2>

<p>The Table Cache is a construct that caches open file descriptors. These file descriptors are for <strong>sstfiles</strong>. An application can specify the maximum size of the Table Cache, or configure RocksDB to <strong>always keep all files open</strong>, to achieve better performance.</p>

<h2 id="io-control">I/O Control</h2>

<p>Users can enable direct I/O so that RocksDB takes full control to the I/O and caching</p>

<h2 id="memtables">Memtables:</h2>

<p>In-memory data structure serving both read and write.</p>

<h3 id="pluggable">Pluggable</h3>

<p>The default implementation of the memtable for RocksDB is a <strong>skiplist</strong>. The skiplist is a sorted set, which is a necessary construct when the workload interleaves writes with range-scans. but it’s useless if there are no range-scan.</p>

<p><strong>Three memtables</strong> are part of the library: a skiplist memtable, a vector memtable and a prefix-hash memtable</p>

<p>​	<strong>A skiplist memtable</strong>:</p>

<p>​	<strong>A vector memtable</strong> is appropriate for bulk-loading data into the database</p>

<p>​	<strong>A prefix-hash memtable</strong> allows efficient processing of gets, puts and scans-within-a-key-prefix.</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20211017175413873.png" alt="image-20211017175413873" /></p>

<h3 id="memtable-pipelining">Memtable pipelining</h3>

<p>RocksDB supports configuring an arbitrary number of memtables for a database.</p>

<p>When a memtable is full   =&gt; 
		Add to flush pipeline =&gt; 
		Background thread flush all the pipelined immutable memtables to storage.</p>

<h3 id="garbage-collection-during-memtable-flush">Garbage Collection during Memtable Flush:</h3>

<p><strong>Flush triggered:</strong></p>

<p>Memtable size, total</p>

<p>Inline compactionprocess is executed when memtable is flushed to the storage,  make sure after flushing, there are no duplicated key in the sstable.</p>

<p>This feature reduces the size of data on storage and write amplification greatly, for some workloads.</p>

<h2 id="merge-operator">Merge Operator</h2>

<p>RocksDB natively supports three types of records, a <code>Put</code> record, a <code>Delete</code> record and a <code>Merge</code> record.</p>

<p>When a compaction process encounters a Merge record, it invokes an application-specified method called the Merge Operator. The Merge can combine multiple Put and Merge records into a single one.</p>

<p>It make read-modify-write operations to avoid read .</p>

<h2 id="write-ahead-log">Write ahead log</h2>

<p>In the event of a failure, write ahead logs can be used to completely recover the data in the memtable, which is necessary to restore the database to the original state</p>

<p>mangodb, cardraeesnal, hbase.</p>

<ol>
  <li>why rocksdb?</li>
</ol>

<p>Embedded application architecture.  where the database is a part of application server</p>

<p>berkeleyDB, SQLite, Kyoto TreeDB, levelDB.</p>

<p>no transaciton log, fixed size keys, h</p>

<p>levelDB, low write rates, only one cpu</p>

:ET