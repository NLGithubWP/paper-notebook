I"<h1 id="introduction">Introduction</h1>

<p>This paper provides some basic background of different concepts and implementation aspects involved in data storage, cloud usage, AI pipelines.</p>

<p>Four essential techniques that can help drive AI applications forward are <strong>data storage, cloud usage, AI pipeline implementation and computation strategy.</strong></p>

<h1 id="data-storage">Data Storage</h1>

<p>Biobank is an ‚ÄúOrganised database of <code>medical images</code> and <code>associated imaging biomarkers (radiology and beyond) shared</code> among multiple researchers and linked to other bio-repositories‚Äù.</p>

<p>THe BioBank dataset can be used in Quantitative Imaging Network (QIN) system:</p>

<p><img src="imgs/image-20220126204752234.png" alt="image-20220126204752234" style="zoom:40%;" /></p>

<p>Challenges and considerations of data:</p>

<ol>
  <li>Label group truth.</li>
  <li>The metadata of dataset (provenance etc) is also important.</li>
</ol>

<h1 id="cloud-usage">Cloud Usage</h1>

<p><img src="imgs/image-20220126205842221.png" alt="image-20220126205842221" style="zoom:35%;" /></p>

<h2 id="characteristics">Characteristics</h2>

<p>On-demand self-service: user can deploy self-defined services and they can automatically expend.</p>

<p>Resource polling: cloud provider can dynamically assign or schedule resources to multiple customers</p>

<p>Repid elasticity: ability of on-demand auto-scaling.</p>

<h2 id="service-model">Service Model</h2>

<p>Cloud can provide services like PaaS, MLaaS, IaaS etc.</p>

<h2 id="deployment-model">Deployment Model</h2>

<p>Private cloud: Exclusive cloud for one organization.</p>

<p>Community cloud: the use is not exclusive to one organization but to multiple organizations.</p>

<p>Public cloud: open to public.</p>

<h1 id="ai-pipeline">AI PipeLine</h1>

<p>Support whole process form data collection to deployment.</p>

<h2 id="local-implementation">Local Implementation</h2>

<p><strong>Networking</strong></p>

<p>The pipeline consist of local storege system, processors, deployment system, and one big challenge is to <code>minilize communicaiton latency</code> of those components. Solutions like:</p>

<ol>
  <li>Reducing model precision by storing single floating point or less rather than double precision.</li>
  <li>Perform compression is to limit the values of gradient updates to binary values.</li>
</ol>

<p><strong>Data Management</strong></p>

<p>Data preparation, storage, processing and exchange between systems.</p>

<p><strong>AI Models</strong></p>

<p>ONNX enables various DL frameworks to share their model properties and co-operate within the same network.</p>

<h2 id="cloud-implementation">Cloud Implementation</h2>

<p>Online annotation, Online training,</p>

<h1 id="distributedfederated-learning">Distributed/Federated Learning</h1>

<p><strong>Methods</strong></p>

<p>Data Parallelism / model Parallelism</p>

<p><strong>Synchronization Training</strong></p>

<p>May suffer from slow worker.</p>

<p><strong>Bounded synchronous training</strong></p>

<p>Using stale parameters to train may reduce the performace, so it needs to add a bound to it</p>

<p><strong>System architectures</strong></p>

<ul>
  <li>Centralized parameter server: slow worker problem, single node failure.</li>
  <li>Decentralized architecture: communication is high but more robust to failure.</li>
  <li>Federated learning architecture: secure parameter transmission, Encryption.</li>
  <li>Sequence model training: a model is trained on data from one insitution and then adapated to new institutions.</li>
</ul>
:ET