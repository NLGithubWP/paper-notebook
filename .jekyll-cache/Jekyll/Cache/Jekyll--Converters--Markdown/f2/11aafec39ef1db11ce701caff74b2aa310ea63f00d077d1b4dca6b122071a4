I"[<h1 id="introduction">Introduction</h1>

<h2 id="problems">Problems</h2>

<ol>
  <li>It’s hard to design task-specific search spaces.</li>
  <li>The search algorithm is tightly bound to search space, and it’s hard to implement every search algorithm once switching to another search space.</li>
</ol>

<p>Current works</p>

<ol>
  <li>
    <p>Train each sampled arch independently from search, =&gt; computationally prohibitive when facing large datasets</p>
  </li>
  <li>
    <p>Weight sharing / network morphism / performance prediction =&gt; case-specific, relying on architecture-specific code</p>

    <p>to work.  It requires lots of engineering work for adapting the search algorithm to a new search space.</p>
  </li>
</ol>

<h2 id="contribution">Contribution</h2>

<ol>
  <li>Integrate many popular NAS search algorithms.</li>
  <li><strong>Decoupling the search spaces, optimization algorithms, network transformations, and evaluation strategies</strong>, each of them is a reusable component.</li>
  <li>Automatically generate search space by replacing modules of a <strong>given</strong> network with integrated components.</li>
  <li>Experiments show the system can be efficiently utilized to carry out architecture searches for various DL applications. (Image classification, speech recognition, recommender system.)</li>
</ol>

<h1 id="framework-design">Framework design</h1>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220509211430805.png" alt="image-20220509211430805" /></p>

<p>Different algorithm requires different ways of initializing the weight.</p>

<h2 id="usage-cases">Usage cases</h2>

<h3 id="subnet-based-search">Subnet based search</h3>

<p>Transform will init the new architecture’s weight from scratch.</p>

<h3 id="supernet-based-search">SuperNet based search</h3>

<p>Transform function selects the corresponding paths specified by alpha.</p>

<h3 id="network-morphism">Network morphism</h3>

<p>For OFA training, the transform just alters the computational graph topology ( decrease or increase the sizes. )</p>

<h2 id="additional-features">Additional features</h2>

<p>Hyperparameter tuning: Reuse the origina frameworks,</p>

<p>Process pipeline: chaining search, training, and hyperparameter tuning processes to form an pipeline. There is a scheduler to schedule the tasks.</p>

<p>Distributed search support: For discrete NAS methods,</p>

<h1 id="evaluation">Evaluation</h1>

<h2 id="setting">Setting</h2>

<h3 id="tasks">Tasks</h3>

<p>Image classification task: Cifar10, Cifar100, ImageNet</p>

<p>Voice recogination task: CTR prediction challenge on Kaggle.</p>

<p>NAS benchmarks: Use the datasets from NASBench101</p>

<h3 id="search-space">Search Space</h3>

<p>Image classification:</p>

<ul>
  <li>cell-based search space,</li>
  <li>ResNet50: search for convolutions with kernel size (3,5,7)</li>
  <li>MobileNetV2: kernel size, expansion ratio of convolutions in each residual block.</li>
</ul>

<p>voice recognition task: ResNet-34 is used as the macro architecture, and variants of ResNet basic blocks are chosen as candidates.</p>

<p>Multi-branch network for the recommendation task. and search for feature interaction layers, including inner product, outer product, and MLPs.</p>

<h2 id="accuracy-result">Accuracy Result</h2>

<p>Mainyl measure the top architecture’s accuracy across different datasets/algorithms/spaces..</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220509213224198.png" alt="image-20220509213224198" /></p>

<h2 id="usability-result">Usability Result</h2>

<p>Evaluate the LOC in implementing NAS, and compare it with other frameworks.</p>

<p>Use voice recognition task,</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220509213812035.png" alt="image-20220509213812035" /></p>

<h2 id="pareto-optimal-search-result">Pareto Optimal Search Result</h2>

<p>Apart from searching for one architecture with the best accuracy, It also explored Pareto optimal architecture search with multi-objective discrete search algorithms, such as genetic algorithms or even random search.</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220509213942089.png" alt="image-20220509213942089" /></p>

<h1 id="details">Details</h1>

<p>The algorithm details are in attachement.</p>
:ET