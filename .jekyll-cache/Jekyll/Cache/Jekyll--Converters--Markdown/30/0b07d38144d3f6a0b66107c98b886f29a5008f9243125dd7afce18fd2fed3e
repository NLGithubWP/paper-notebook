I"B<h1 id="introduction">Introduction</h1>

<h2 id="motivation">Motivation</h2>

<p>Find an architecture without training is needed</p>

<h2 id="contributions">Contributions</h2>

<p>The paper uses activations overlap between datapoints in untrained networks to measure the networkâ€™s performance.</p>

<p>The paper evaluates the algorithm on NAS-Bench-101, NAS-Bench-201, NATS-Bench, and Network Design Spaces.</p>

<h1 id="score-method">Score method</h1>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220603151641071.png" alt="image-20220603151641071" /></p>

<h1 id="evaluation">Evaluation</h1>

<p>We are able to search for a network that achieves 92:81% accuracy in 30 seconds within the NAS-Bench-201 search space.</p>

<h2 id="correlation-of-accuracy--score">Correlation of Accuracy &amp; Score</h2>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220603152020083.png" alt="image-20220603152020083" /></p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220603152008978.png" alt="image-20220603152008978" /></p>

<p>These results point to our score being effective on a wide array of neural network design spaces.</p>

<h2 id="study">Study</h2>

<ol>
  <li>How important are the images used to compute the score?</li>
</ol>

<p>In the paper, we randomly select 10 architectures from different CIFAR-100 accuracy percentiles in NAS-Bench-201 and compute the score separately for 20 random CIFAR-100 mini-batches.</p>

<p>This suggests our score captures a property of the network architecture, rather than something data-specific.</p>

<ol>
  <li>Does the initialization influence the score?</li>
</ol>

<p>better-performing networks remain distinctive and can be isolated</p>

<ol>
  <li>Does the size of the mini-batch matter?</li>
</ol>

<p>The best-performing networks remain distinct.</p>

<ol>
  <li>How does the score evolve as networks are trained ?</li>
</ol>

<p>We observe that the score increases in all cases immediately after some training has occurred.</p>

:ET