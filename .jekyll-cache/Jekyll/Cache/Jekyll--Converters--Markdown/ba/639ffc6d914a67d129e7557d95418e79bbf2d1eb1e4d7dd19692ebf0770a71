I"…+<h1 id="introduction">Introduction</h1>

<h2 id="current-problems">Current Problems</h2>

<p>Cohort analysis is about comparing a different group of users, and grouping is based on events or times users start a service.</p>

<p>Cohort steps:</p>

<ol>
  <li><code>Find birth user cohort:</code> group users experiencing similar given events to an affiliate.</li>
  <li><code>Segmentation:</code> for each cohort, assign the records into diverse segments.</li>
  <li><code>Aggregation:</code> for each segment, measure using a given aggregator.</li>
</ol>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220610222932147.png" alt="image-20220610222932147" /></p>

<p>However, the OLAP system (<em>MonetDB</em>, <em>Druid</em>) is inefficient in processing complex cohort queries. However, they use <code>columnar architecture</code> to scale up or take advantage of <code>distributed processing</code> for <code>specific queries</code>.</p>

<p>It is non-trivial to <code>integrate both of them together.</code></p>

<h2 id="contributions">Contributions</h2>

<p>The paper proposes Cool, a cohort OLAP system. It supports both OLAP and emerging cohort queries for data analytics with superb performance.</p>

<ol>
  <li>The system includes:
Two operators for OLAP query (metal chunk selector, dataChunk selector).
Three operators for cohort query (birth selector, age selector, cohort aggregator.)</li>
  <li>The system design a sophisticated storage layout to optimize query processing and space consumption. It stores precomputation results to boost OLAP execution.</li>
  <li>Scale the system with HDFS and Zookeeper. The system can recover from failures.</li>
  <li>Compare Cool with Druid, and MonetDB in a single-node setting. 
Compare Cool with SparkSQL and distributed Druid in a distributed setting.</li>
</ol>

<p>Cool differs with Cohana in following:</p>

<ol>
  <li>Cool, use more general definition for cohort queries. It employs a sequence of birth events to find the valid users.</li>
  <li>Cool support conventional cube queries.</li>
  <li>Cool can be distributed.</li>
</ol>

<h1 id="related-work">Related Work</h1>

<p>The existing system can be divided into:</p>

<ol>
  <li>conventional OLAP systems built on top of DBS.</li>
  <li>specific query engines for specific query types.</li>
</ol>

<h2 id="conventional-olap">Conventional OLAP</h2>

<h3 id="columnar-architecture">columnar architecture</h3>

<p>Most of them use <code>columnar stores</code> because</p>

<ol>
  <li>OLAP queries normally scan a large volume of a limited set of columns, and <code>columnar store</code> can only load the required column.</li>
  <li>In columnar store, the scanned data can be further shrunk by <strong>compression</strong> such as dictionary encoding, run length encoding. Row re-ordering encoding, etc.</li>
</ol>

<p>But the <code>data insertion and point query</code> are worse than <code>row-oriented</code> database.</p>

<p>So hybrid storage is proposed, it combines both row-oriented store and columnar store together within one system,</p>

<p>eg,. MemSQL, SAP HANA, Oracle Database in-memory Hyper.</p>

<h3 id="distributed-processing">Distributed processing</h3>

<p>To handle enormous amount of data, OLAP system also supoorts distributed processing. such as Hive,  Qylin. But it normally depends on worker resources.</p>

<h2 id="emerging-query-engines">Emerging Query Engines</h2>

<p>Point offers a real-time response for iceberg queries.( prevailing type of query selecting a small number of records that satisfy some given conditions.)</p>

<p><strong>Data structure/indexs</strong></p>

<p><code>Data cube</code> is widely used for queries involving multiple dimensions from dataset.</p>

<p><code>Start-Tree</code> is used to support OLAP queries.</p>

<p><strong>Compression</strong></p>

<p>New compression algorithms also proposed to improve the performance</p>

<ol>
  <li>PowerDrill use two-level dictionary compression schema to enable processing of trillion record cells in seconds.</li>
  <li>Condensed cube reduce size of cube and imporive the computation time.</li>
</ol>

<p><strong>Injection</strong></p>

<p>Spark used to handle stream queries. 
Shark further improves its performance by leveraging distributed memories.</p>

<h1 id="single-node-architecture">Single Node Architecture</h1>

<p>Loader, controller, parser, planner, compressor and executor.</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220223164904589.png" alt="image-20220223164904589" /></p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220328230147873.png" alt="image-20220328230147873" /></p>

<h2 id="data-model">Data Model</h2>

<p>Each table is horizontally split into different partitions called cublets.</p>

<p>Each cublet consists of multiple chunks (data chunk, meta chunk, header, header offset)</p>

<h2 id="storage-layout">Storage Layout</h2>

<p><strong>Chunks</strong></p>

<ul>
  <li><code>DataChunk:</code> Cool transcripts <code>columnar data</code> into field inside DataChunk.</li>
  <li><code>MetaChunk:</code> is used to store the metadata <code>for each dataChunk</code> within the same cublet, including number of contained fields and range of each field</li>
  <li><code>Header</code>: store the number of data chunks.</li>
  <li><code>Header offset</code>: store headerâ€™s position.</li>
</ul>

<p><strong>Field Types:</strong></p>

<ul>
  <li>Range: integer, float, time,</li>
  <li>world: string, event.</li>
</ul>

<p>the system has different storage plan for different filed type.</p>

<p><strong>Storage plan</strong></p>

<ul>
  <li>For range filed: only keep max/min value</li>
  <li>For the world field: apply a double dictionary schema to save space.</li>
</ul>

<p><strong>Compression</strong></p>

<p>Firstly, each field is encoded to reduce space usage.</p>

<ul>
  <li>Numbers are translated into a lock dict</li>
  <li>the distinct string is put into a global dictionary and can be indexed by a unique number.</li>
</ul>

<p>Besides, compression is also used.</p>

<ul>
  <li>bit packing and vectorization are introduced to deal with delta values and dictionary indexing numbers.</li>
</ul>

<h2 id="query-processing">Query Processing</h2>

<p><strong>Two operators for OLAP query:</strong></p>

<ol>
  <li>
    <p>MetaChunk selector: (schema of chunkD, MetaChunk M, predicate tree P) =&gt; traverse M with P =&gt; whether the chunk contains data.</p>
  </li>
  <li>
    <p>DataChunk selector: find matched data records in query processing.</p>

    <p>(dataChunk R, Record Number N, predicate tree P) =&gt; bites B (indexs of records)</p>
  </li>
</ol>

<p><strong>Three operators for cohort query</strong></p>

<ol>
  <li>Birth selector: capture qualified users. (MetaChunk M, dataChunk, predicate tree P) =&gt; where the events in birth event sequence exist in scanning chunk.</li>
  <li>Age selector: (dataChunk, predicate tree P, bitset B) =&gt; marking whether the user can be selected for aggregation in age.</li>
  <li>Cohort aggregator: the records that pass both above selectors can be aggregated.</li>
</ol>

<p><strong>OLAP Processing Flow</strong></p>

<ol>
  <li><code>Planner</code> =&gt; generate execution plan</li>
  <li>Fetch a <code>cublet</code> from specified data source.</li>
  <li><code>MetaChunk selector</code> =&gt; find <code>cublet</code> with candidate values</li>
  <li>Repeat form 2 unit find a <code>cublet</code></li>
  <li><code>DataChunk selector</code> =&gt; find records.</li>
  <li><code>Aggregators</code> on the scanning result and group the results;</li>
  <li>Repeat from 2 until all cublets are processed.</li>
  <li><code>Compressor</code>: compress and store agggregate results</li>
</ol>

<p><strong>Cohort Query Processing</strong></p>

<ol>
  <li><code>Planner</code> =&gt; generate execution plan</li>
  <li>Fetch a <code>cublet</code> from the specified data source.</li>
  <li><code>MetaChunk selector</code> =&gt; find <code>cubelet</code> with the <code>birth event in sequence</code></li>
  <li>Repeat form 2 unit find a <code>cubelet</code></li>
  <li><code>Birth selector</code> =&gt; scan data chunk to find users.</li>
  <li><code>Age selector</code> =&gt; calculate ages.</li>
  <li><code>Aggregator</code>: aggregate cohorts from the user.</li>
  <li>Repeat from 2 until all cubelets are processed.</li>
  <li><code>Compressor</code>: compress and store aggregate results</li>
</ol>

<h1 id="distributed-system-architecture">Distributed System Architecture</h1>

<p><img src="imgs/image-20220224155711239.png" alt="image-20220224155711239" style="zoom:50%;" /></p>

<h1 id="performance-evaluation">Performance Evaluation</h1>

<h2 id="experiment-setup">Experiment setup</h2>

<p>Compare with Apache Druid, (OLAP related query evaluation)</p>

<p>MonetDB (columnar analytical dataabse for cohort query evaluation)</p>

<p>SparkSQL/Distributed Druid(distributed processing)</p>

<p><strong>Matrix</strong></p>

<p>Query latency / compression ratio / memory consumption in processing.</p>

<p><strong>Workloads</strong></p>

<p>TPC-H benchmark / medical dataset MED</p>

<p><strong>Queries</strong></p>

<p>Cohort Query: used to measure cohort analysis query processing</p>

<p>IceBerg Query (OLAP): used to measure performance of selector in COOL</p>

<p>Cube query</p>

<p>Composite Query</p>

<p><img src="imgs/image-20220224161909225.png" alt="image-20220224161909225" style="zoom: 67%;" /></p>

<h2 id="latency">Latency</h2>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220224162311451.png" alt="image-20220224162311451" /></p>

<p><em>MonetDB</em>incurs more disk accesses during the processing compared to <em>Cool</em></p>

<p>And the frequent data swapping, from disk to memory slows down the system performance in terms of query latency.</p>

<h2 id="processing-memory">Processing Memory</h2>

<p><img src="imgs/image-20220224163016138.png" alt="image-20220224163016138" style="zoom: 67%;" /></p>

<p>First, <em>Druid</em> needs to maintain auxiliary system components in order to manage the data segments, which is complex and incurs high overhead. However, <em>Cool</em> exploits a relatively simple storage hierarchy and therefore eliminates such extra costs.</p>

<p>Second, <em>Druid</em> must map the data from disk to memory during query processing even for the tiny dataset while for <em>Cool</em>, due to the highly <code>compressed</code> cublet structures, it may keep the entire dataset in memory for small datasets, which further leads to the performance gap between the two systems.</p>

<h2 id="multi-node-benchmark"><em>Multi-node Benchmark</em></h2>

<p>Employ <code>1 to 16 nodes to</code> evaluate the system performance</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220224163329949.png" alt="image-20220224163329949" /></p>

<p>SparkSQL: merge of all the results, instead of the computation of each parquet partition, dominates the system performance.</p>

:ET