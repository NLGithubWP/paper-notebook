I"N<p>[JMLR-2019] Neural Architecture Search: A Survey</p>

<p>Problems:</p>

<ol>
  <li>review some basic knowledge about Reinforcement learning, and Bayesian optimization.</li>
</ol>

<h1 id="introduction">Introduction</h1>

<p>The paper categorizes methods for NAS according to three dimensions: <code>Search space, Search strategy and Performance estimation strategy.</code></p>

<p><img src="imgs/image-20220129213313581.png" alt="image-20220129213313581" style="zoom:40%;" /></p>

<p><code>search space</code></p>

<p>Incorporating prior knowledge about architecture and tasks can reduce the search space, but introduce human bias.</p>

<p><code>Search strategy</code>:</p>

<ul>
  <li>Goal1: Find well-performing architectures as quickly as possible.</li>
  <li>Goal2: Avoid convergence to a region of suboptimal architectures.</li>
</ul>

<p><code>Performance Estimation Strategy</code></p>

<ul>
  <li>Goal1: Find architectures that achieve high predictive performance on the validation dataset.</li>
  <li>Goal2: Reduce as much evaluation cost as possible</li>
</ul>

<h1 id="search-space">Search Space</h1>

<h2 id="chain-structured-neural-networks">Chain-structured Neural Networks</h2>

<p>layer l0’s output is l1’s input.</p>

<p>search space is parameterized by</p>

<ol>
  <li>number of layers n</li>
  <li>type or operations very layer execution, eg., pooling, convolution, etc</li>
  <li>Hyperparameters of each layer</li>
  <li>number of fully-connected networks.</li>
</ol>

<h2 id="multi-branch-networks">multi-branch networks</h2>

<p>input of layer i can be formally described as a function G() combining previous layer outputs</p>

<p><img src="imgs/image-20220129220210912.png" alt="image-20220129220210912" style="zoom:50%;" /></p>

<h2 id="blockcell-based-networks">Block/cell-based networks</h2>

<p>Two kinds of cells: Normal cells that preserve dimensionality of input and reduction cell reduce spatial dimension.</p>

<p>Final architecture is built by stacking cells in <code>predified manner</code>.</p>

<p><img src="imgs/image-20220129225010980.png" alt="image-20220129225010980" style="zoom:50%;" /></p>

<p>Advantages:</p>

<ol>
  <li>Search space is redued because cell has less layers.</li>
  <li>Architecture built from cells can more easily be transferred or adapted to other dataset.</li>
  <li>Creating architecture by repeating blocks is a more useful design.</li>
</ol>

<h2 id="blockcell-based-new-design">Block/cell-based New design</h2>

<p>How to choose the macro-architecture: how many cells shall be used and how should they be connected to build the actual model? Hard-coded macro architecture:</p>

<ul>
  <li><code>Each cell receives the outputs of the two preceding cells as input.</code></li>
  <li>Manually designed architectures, eg., DenseNet</li>
</ul>

<p>In general the cell based searching includes 3 steps:</p>

<ol>
  <li>Define a set of primitive operations</li>
  <li>connect primitive operations and form the cell</li>
  <li>Hard-coded macro-architecture.</li>
</ol>

<h1 id="search-strategy">Search Strategy</h1>

<p>Search strategies: random search, Bayesian optimization, evolutionary methods, reinforcement learning, and gradient-based methods.</p>

<h2 id="bayesian-optimization">Bayesian Optimization</h2>

<p>Some papers derive kernel functions for architecture search spaces in order to use classic GP-based BO methods</p>

<p>Optimize both neural architectures and their hyperparameters jointly.</p>

<p>##</p>

<h2 id="reinforcement-learning-method">reinforcement learning method</h2>

<p>Agent’s action: Generation of a neural architecture with action space: identical to the search space.</p>

<p>Agent’s reward: Estimate of the performance of the trained architecture on unseen data.</p>

<p>Different RL approaches differ in how they represent the agent’s policy and how they optimize it.</p>

<ol>
  <li>Recurrent neural network (RNN) policy to sequentially sample a string that in turn encodes the neural architecture.</li>
  <li>Q-learning to train a policy which sequentially chooses a layer’s type and corresponding hyperparameters.</li>
</ol>

<h2 id="sequential-decision-processes">Sequential decision processes</h2>

<p>state is the current (partially trained) architecture</p>

<p>reward is an estimate of the architecture’s performance</p>

<p>action corresponds to an application of function-preserving mutations followed by a training phase of the network.</p>

<h2 id="evolutionary-method">Evolutionary method</h2>

<p>Using gradient-based methods for optimizing weights and solely use <code>evolutionary algorithms</code> for optimizing the neural architecture itself.</p>

<p>in every evolution step, at least <code>one model from the population is sampled</code> and serves as a <code>parent</code> to <code>generate offsprings</code> by applying mutations to it. In the context of NAS, mutations are local operations, such as adding or removing a layer, altering the hyperparameters of a layer, adding skip connections, as well as altering training hyperparameters. <code>After training the offsprings, their fitness (e.g., performance on a validation set) is evaluated and they are added to the population</code>.</p>

<p><strong>Challenge</strong></p>

<ol>
  <li>how to sample parents</li>
  <li>update populations</li>
  <li>generate offsprings</li>
</ol>

<h2 id="compare">Compare</h2>

<p>RL and evolution perform equally well in terms of final test accuracy, with evolution having better anytime performance and finding smaller models.</p>

<p>Random search test error = 3.9% on CIFAR-10 and a top-1 validation error of 21.0% on ImageNet.</p>

<p>Evolution-based method: 3.75% and 20.3% respectively.</p>

<h1 id="performance-estimation-strategy">Performance Estimation Strategy</h1>

<p>To guide the search process, these search strategies need to estimate the performance of a given architecture A they consider.</p>

<p><img src="imgs/image-20220130200229344.png" alt="image-20220130200229344" style="zoom:50%;" /></p>

<h2 id="lower-fidelity-estimates">Lower fidelity estimates</h2>

<h2 id="learning-curve-extrapolation">Learning Curve extrapolation</h2>

<p>Consider architectural hyperparameters for predicting which partial learning curves are most promising.</p>

<p><strong>Challenge</strong></p>

<p>The main challenge for predicting the performances of neural architectures is good predictions in a relatively large search space need to be made based on relatively few evaluations.</p>

<h2 id="one-shot-models">One-Shot Models</h2>

<p><img src="imgs/image-20220130202859073.png" alt="image-20220130202859073" style="zoom:50%;" /></p>

<p>Treats all architectures as different sub-graphs of a supergraph (the one-shot model) and shares weights between architectures that have edges of this supergraph in common.</p>

<p>Only the weights of a single one-shot model need to be trained (in one of various ways), and architectures (which are just subgraphs of the one-shot model) can then be evaluated without any separate training by inheriting trained weights from the one-shot model.</p>

<p><strong>Challenge</strong></p>

<p>How the one-shot model is trained.</p>

<h1 id="future-directions">Future Directions</h1>

:ET