I"€<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220516175455266.png" alt="image-20220516175455266" /></p>

<h1 id="hyperband">HyperBand</h1>

<p>The successive halving method suffers from a trade-off between selecting the number configurations and allocating the budget. To solve this problem, HyperBand proposed to frequently perform the successive halving method with different budgets to find the best configurations.</p>

<h2 id="algorithm">Algorithm</h2>

<p>R: the maximum amount of resource that can be allocated to a single configuration</p>

<ol>
  <li>the training set size for dataset downsampling;</li>
  <li>limitations based on memory constraints for feature downsampling;</li>
  <li>rule of thumb regarding the number of epochs when iteratively training neural networks</li>
</ol>

<p>1/Î·: how many configurations to retain in each round. if Î·=3. each round retains 1/3 configurationsã€‚</p>

<ol>
  <li>A large value corresponds to fewer rounds of elimination, and an aggressive elimination schedule.</li>
</ol>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220519163826743.png" alt="image-20220519163826743" /></p>

<h1 id="example">Example</h1>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220516180728966.png" alt="image-20220516180728966" /></p>

:ET