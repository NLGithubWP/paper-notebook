I"¯<h1 id="abstract--introduction">Abstract &amp; Introduction</h1>

<p>The paper proposes an algorithm for decision tree training in VFL, it provides protection against a semi-honest adversary.</p>

<h2 id="motivation">Motivation</h2>

<p>Existing work mainly focuses on the horizontal setting. and VFL is needed. While some VFL algorithm has some limitations in either efficiency or data privacy.</p>

<ol>
  <li>Some work requires labels must be in plaintext across all parties.</li>
  <li>Some work assumes intermediate results can be revealed in plaintext.</li>
  <li>Some work replies on secure hardware, but the hardware may not be trusted by all parties and can be vulnerable to side-channel attacks.</li>
  <li>Some work use MPC but assume the client can outsource the data into non-colliding servers.</li>
</ol>

<h2 id="contribution">Contribution</h2>

<p>Propose a system, that does not rely on any trusted third party.</p>

<p>It is a hybrid framework that utilizes both <strong>threshold partially homomorphic encryption (TPHE) and MPC</strong></p>

<ol>
  <li>TPHE: efficient communication cost, but only support some computations</li>
  <li>MPC: support arbitrary computations but has high communication overhead.</li>
</ol>

<p>It uses TPHE as much as possible for local computations and only invokes MPC in places where TPHE is inadequate in terms of functionality.</p>

<p>The results demonstrate good accuracy comparable to non-private algorithms and high efficiency.</p>

<p>The basic and enhanced protocols of Pivot achieve up to 37.5x and 4.5x speedup (w.r.t. training time) over an MPC baseline.</p>

<h1 id="preliminaries">Preliminaries</h1>

<h2 id="tphe">TPHE</h2>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623151445071.png" alt="image-20220623151445071" /></p>

<h2 id="mpc">MPC</h2>

<p>it allows participants to compute a function over their inputs while keeping the inputs private.</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623152158698.png" alt="image-20220623152158698" /></p>

<h1 id="solution-overview">Solution Overview</h1>

<p>Assume:</p>

<ol>
  <li>Pivot focuses on the vertical federated learning scenario where each party shares the duplicate sample ids with different features.</li>
  <li>Label set Y is held by only activate party and cannot be directly shared with other clients.</li>
  <li>Semi-host model. ALL parties have to follow the exact prespecified protocol</li>
</ol>

<p>Protocol overview</p>

<ol>
  <li>All parties jointly generate the keys of TPHE, and each part has PK and part of SK.</li>
  <li>Begin computation. In each iteration,  <code>PlainText =&gt; Cipher =&gt; secretly shared values =&gt; compute =&gt; secretly shared values  =&gt; Cipher</code></li>
</ol>

<p>In the basic algorithm, after training, each client will get a tree model in plaintext.</p>

<p>In the enhanced algorithm, the model is in secretly shared form.</p>

<h1 id="basic-protocol">Basic Protocol</h1>

<h2 id="computation">Computation</h2>

<ol>
  <li>encrypted mast vector to indicate which samples are available.</li>
  <li>Local computations</li>
  <li>MPC computations</li>
</ol>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623160431397.png" alt="image-20220623160431397" /></p>

<h2 id="secure-guarantees">Secure guarantees</h2>

<p>TPHE =&gt; local computations and model updates are secure</p>

<p>MPC =&gt; MPC computation step is secure.</p>

<h1 id="enhance-protocol">Enhance protocol</h1>

<p>The final model is plaintext, it could leak label and feature value information.</p>

<p>Clients are able to split the sample set based on the split information in the model and their own datasets.</p>

<p>The enhanced protocol saves the model in a secretly shared form and then proposes some methods to conduct prediction on it.</p>

<h1 id="experiments">Experiments</h1>

<p>Datasets:</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623161848084.png" alt="image-20220623161848084" /></p>

<p>Baselines:</p>

<ol>
  <li>Accuracy: compare with sklearn, MSE/precision.</li>
  <li>Efficiency: compare with the pure secret sharing-based algorithm implemented in the MPC method.  and measure
    <ul>
      <li>the total running time of the model training stage</li>
      <li>the prediction running time <strong>per sample</strong> of the model prediction stage.</li>
    </ul>
  </li>
</ol>

<h2 id="accuracy">Accuracy</h2>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623162227694.png" alt="image-20220623162227694" /></p>

<h2 id="efficiency-of-training">Efficiency of training</h2>

<p>m: number of clients</p>

<p>n: number of samples</p>

<p>d: number of features</p>

<p>b: number of splits</p>

<p>d: number of features.</p>

<p>h: tree depth</p>

<p>W: Number of trees.</p>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623162307009.png" alt="image-20220623162307009" /></p>

<h2 id="training-of-inference">Training of inference</h2>

<p><img src="https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623162703338.png" alt="image-20220623162703338" /></p>

<h1 id="further-protection">Further protection</h1>

<ol>
  <li>As for malicious adversaries, we can extend the system into zero-knowledge proofs (ZKP), and SPDZ with authenticated shares.</li>
</ol>
:ET