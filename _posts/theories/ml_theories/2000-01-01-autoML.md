---
title: black-box optimization
date: 2021-08-12
layout: post
active: journal
header-img: "img/postcover/post02.jpg"
categories: [machine learning basic]
---
# 超参数优化

常用的超参数优化方法有

1. 网格搜索（Grid search），
2. 随机搜索（Random search），
3. 遗传算法，
4. 贝叶斯优化（Bayesian Optimization）

# 核函数

![image-20220513171159519]({{ site.baseurl }}/img/tech-book-img/image-20220513171159519.png)

高斯过程，SVM， PCA都是核函数学习的例子

## 特征映射

把一个数据从低维空间映射到高维空间，使得**高维空间下，数据更容易分类（线性可分的）**

如果映射函数是 f(x), 对于任意2条数据，loss函数可能需要算这个2个数据 映射完的内积，即算 `f(x1). f(x2)`

把它定义为核函数， 即  `K(x1, x2) = f(x1). f(x2)`

有了这个定义后，可以直接定义核函数的形式，而不用具体定义f(x) 的形式。

# 概率图模型

概率图模型分为三种：**贝叶斯网络，马尔科夫随机场**以及**高斯网络**

# 高斯

## 高斯网络

多维度高斯分布， 变量直接相互独立，更容易求出mean和方差矩阵。

## 高斯过程

举例：

一个人在同一时刻有不同表现，每个表现出现的概率服从高斯分布，不同时刻都会有一个高斯分布。

![image-20220513185251560]({{ site.baseurl }}/img/tech-book-img/image-20220513185251560.png)

不同时刻的表现，构成了一个高斯过程的一个高斯样本。







# [贝叶斯优化](https://www.cnblogs.com/marsggbo/p/9866764.html)

## black-box optimization

![image-20220513212019154]({{ site.baseurl }}/img/tech-book-img/image-20220513212019154.png)

1. init sample
2. init mode
3. get acquisition fuction
4. optimize x_next = argmax(af)
5. sample new data and update model.
6. repeat









![image-20220513165947325]({{ site.baseurl }}/img/tech-book-img/image-20220513165947325.png)

![image-20220511113932104]({{ site.baseurl }}/img/tech-book-img/image-20220511113932104.png)

# background

## Hyeperband algorithm

asdf



## BO

sdf