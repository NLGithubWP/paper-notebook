---
title: Privacy Preserving Vertical Federated Learning for Tree-based Models
header-img: "img/postcover/post02.jpg"
categories: [A paper note]
layout: post
---

# Abstract & Introduction

The paper proposes an algorithm for decision tree training in VFL, it provides protection against a semi-honest adversary.

## Motivation

Existing work mainly focuses on the horizontal setting. and VFL is needed. While some VFL algorithm has some limitations in either efficiency or data privacy. 

1. Some work requires labels must be in plaintext across all parties. 
2. Some work assumes intermediate results can be revealed in plaintext. 
3. Some work replies on secure hardware, but the hardware may not be trusted by all parties and can be vulnerable to side-channel attacks.
4. Some work use MPC but assume the client can outsource the data into non-colliding servers.

## Contribution

Propose a system, that does not rely on any trusted third party.

It is a hybrid framework that utilizes both **threshold partially homomorphic encryption (TPHE) and MPC**

1. TPHE: efficient communication cost, but only support some computations
2. MPC: support arbitrary computations but has high communication overhead.

It uses TPHE as much as possible for local computations and only invokes MPC in places where TPHE is inadequate in terms of functionality.

The results demonstrate good accuracy comparable to non-private algorithms and high efficiency. 

The basic and enhanced protocols of Pivot achieve up to 37.5x and 4.5x speedup (w.r.t. training time) over an MPC baseline.

# Preliminaries

## TPHE

![image-20220623151445071](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623151445071.png)

## MPC

it allows participants to compute a function over their inputs while keeping the inputs private.

![image-20220623152158698](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623152158698.png)

# Solution Overview

Assume:

1. Pivot focuses on the vertical federated learning scenario where each party shares the duplicate sample ids with different features.
2. Label set Y is held by only activate party and cannot be directly shared with other clients. 
3. Semi-host model. ALL parties have to follow the exact prespecified protocol

Protocol overview

1. All parties jointly generate the keys of TPHE, and each part has PK and part of SK.
2. Begin computation. In each iteration,  `PlainText => Cipher => secretly shared values => compute => secretly shared values  => Cipher`

In the basic algorithm, after training, each client will get a tree model in plaintext.

In the enhanced algorithm, the model is in secretly shared form.

# Basic Protocol

## Computation

1. encrypted mast vector to indicate which samples are available. 
2. Local computations
3. MPC computations

![image-20220623160431397](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623160431397.png)

## Secure guarantees

TPHE => local computations and model updates are secure

MPC => MPC computation step is secure.

# Enhance protocol

The final model is plaintext, it could leak label and feature value information.

Clients are able to split the sample set based on the split information in the model and their own datasets.

The enhanced protocol saves the model in a secretly shared form and then proposes some methods to conduct prediction on it. 

# Experiments

Datasets:

![image-20220623161848084](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623161848084.png)



Baselines:

1. Accuracy: compare with sklearn, MSE/precision.
2. Efficiency: compare with the pure secret sharing-based algorithm implemented in the MPC method.  and measure 
   - the total running time of the model training stage  
   - the prediction running time **per sample** of the model prediction stage.

## Accuracy

![image-20220623162227694](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623162227694.png)

## Efficiency of training

m: number of clients

n: number of samples

d: number of features

b: number of splits

d: number of features.

h: tree depth

W: Number of trees. 

![image-20220623162307009](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623162307009.png)

## Training of inference

![image-20220623162703338](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220623162703338.png)

# Further protection

1. As for malicious adversaries, we can extend the system into zero-knowledge proofs (ZKP), and SPDZ with authenticated shares.
