---
title: NAS-BENCH-201 EXTENDING THE SCOPE OF REPRODUCIBLE NEURAL ARCHITECTURE SEARCH
header-img: "img/postcover/post02.jpg"
categories: [A paper note]
layout: post
---

# Introduction

The paper introduces the NAS-Bench-201, which is extended from NAS-Bench-101. 

## Motivation

Previously NAS-Bench-101 and NAS-HPO-Bench are proposed. However, 

1. some NAS algorithms can not be applied directly on NASBench-101.

   101 has constraints on the nodes/edges of each cell. Some NAS algorithms based on weight-sharing cannot be applied into it.

2. NAS-HPO-Bench only has 144 candidate architectures, which may be insufficient to evaluate NAS algorithms.

## Contributions

In summary, the paper makes the following contributions.

1. The search space: Cell-based, each cell has **4 nodes and 5 operations**, which results in 15625 cell/architectures candidates in total. 
2. Each architecture is trained on three datasets (CIFAR10, CIFAR100, ImageNet-16-120 ), and the paper records their loss, accuracy, number of parameters, and FLOPs.
3. The paper benchmarked **10 NAS algorithms** on the above search space.

# NAS-Bench-201

![image-20220531162907710](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220531162907710.png)

![image-20220531162924350](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220531162924350.png)

![image-20220531162938041](https://github.com/NLGithubWP/tech-notebook/raw/master//img/a_img_store/image-20220531162938041.png)

# Discussion