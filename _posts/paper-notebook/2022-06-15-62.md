---
title: HNAS
header-img: "img/postcover/post02.jpg"
categories: [A paper note]
layout: post
---

# Introduction

## Motivation & Contriubtion

The paper tries to answer 2 questions

1. what is the relationship between 4 training-tree NAS algorithms? 
2. How to prove the transferability of training-free NAS algorithms theoretically.

# Candidate algs

![image-20220704211411467](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220704211411467.png)

# Connections

The paper uses many inequality theories to prove that all other matrices can be calculated with M_trace.

![image-20220704211437162](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220704211437162.png)

The paper examines the Spearman correlation between each matrix with M_trace on **a batch of randomly sampled data** from C10.

# Transferability

## Algo generalization  performance over Search space 

At first, the paper tries to answer the question: **Why do existing training-free NAS algorithms with these metrics achieve compelling performances in practice?**

The method the paper uses is to get some relationship between **loss on test-dataset and metrics.** It shows the loss on test datasets is upper bounded by the metrics.

According to the equation, for a non-realizable scenario

1. Larger M => better generalization performnace. 
2. When M > mc/n, there is a trade-off in M between converging and transferability. Larger M => slow convergence, but a small gap.

![image-20220704212924967](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220704212924967.png)

A larger positive number implies a better agreement between the matrix and the architecture performance. 

## Architecture transferability over Datasets

And then the paper tries to find if an **architecture** selected using the training-free metric on a dataset S0 is also likely to produce compelling performances on **another dataset** S1.

The method the paper uses is to get the relationship between **loss on the test dataset and the metrics got from another dataset.**

![image-20220704220845428](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220704220845428.png)

# Overall performance

Finally, the paper proposes an algorithm to find architecture quickly.

And the algorithm is to minimize the upper bound of the test error.

![image-20220704221906785](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220704221906785.png)

mu and v are hyperparameters and can be searched using BO. and set t = 1 in practice.

![image-20220704221621969](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220704221621969.png)

![image-20220704222033571](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220704222033571.png)

