---
title: KNAS Green Neural Architecture Search
header-img: "img/postcover/post02.jpg"
categories: [A paper note]
layout: post
---

The paper tries to evaluate architecture without training based on the Gram Matrix of gradients of a mini-batch. 

### provement

Overall, the paper tries to find how the loss is related to the gradient of a mini-batch. 

![image-20220707144931469](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220707144931469.png)

Finally, the paper se the mean of GM - MGM - to evaluate an architecture.

![image-20220707145116956](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220707145116956.png) 

In practice, since the weight is too long, so the paper use sampling to only use a party of weights. 

![image-20220707145215773](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220707145215773.png)

### Algorithm

![image-20220707145234438](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220707145234438.png)

### Evaluation

![image-20220707145500009](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220707145500009.png)

The result shows that MGM has a good coefficient with real performance.

![image-20220707145548608](https://github.com/NLGithubWP/tech-notebook/raw/master/img/a_img_store/image-20220707145548608.png)

This result shows that the 

1. KNAS is faster than search-based and gradient-based evaluation algorithms, and also has a good performance than them.
2. KNAS is slower than training-free based algorithm but has better Acc on ImageNet than those 2. 

